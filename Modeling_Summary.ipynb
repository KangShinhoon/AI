{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling Summary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEVLkvQ6oVS_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_data22 = pd.read_csv(\"/content/df_data22.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = ['Year','Month','Day','Week','Holiday','Covid','Promotion','temp','last']\n",
        "label = ['Sales']\n"
      ],
      "metadata": {
        "id": "wzDSozjTofOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "parameters = {'n_estimators':[25, 50,100],'max_depth':[1,2,3,4,5], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid=parameters, cv=2, refit=True, return_train_score=True)\n",
        "grid_rf.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_rf.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "d-54vpBYojYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "features = ['Year','Month','Day','Week','Holiday','Search','Covid','Promotion','temp','last']\n",
        "label =  ['Sales']\n",
        "x = features\n",
        "y = label\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(df_data22[x] , df_data22[y], test_size = 0.2, shuffle = True, random_state = 20)\n",
        "dt = DecisionTreeRegressor()\n",
        "\n",
        "parameter = {\t'max_depth' :[3,4,5,6,7,8,9], 'min_samples_split' : [1,2,3,4,5,6]}\n",
        "\n",
        "grid_tree = GridSearchCV(dt, param_grid = parameter, cv=2, refit = True, return_train_score=True)\n",
        "grid_tree.fit(x_train,y_train)\n",
        "\n",
        "scores_df = pd.DataFrame(grid_tree.cv_results_)\n",
        "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score']]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gr0I5bXbom5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minmax_scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "minmax_scaler.fit(x_train)\n",
        "\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "\n",
        "x_test = minmax_scaler.transform(x_test)\n"
      ],
      "metadata": {
        "id": "oSNt464mouE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LGBMRegressor\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier \n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(x_train)\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "x_test = minmax_scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "lgbm = LGBMRegressor(random_state=20) \n",
        "\n",
        "parameters = {'n_estimators':[80,90,100,110,120],'max_depth':[5, 10, 15, 20], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_lgbm = GridSearchCV(lgbm, param_grid=parameters, cv=2, refit=True)\n",
        "grid_lgbm.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_lgbm.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "nPiSLscAo_2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GBR\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier \n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(x_train)\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "x_test = minmax_scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "gbr = GradientBoostingRegressor(random_state=20)\n",
        "\n",
        "parameters = {'n_estimators':[100,110,120,130,140,150],'max_depth':[1,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_gbr = GridSearchCV(gbr, param_grid=parameters, cv=2, refit=True)\n",
        "grid_gbr.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_gbr.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "NZAbHCL2pH7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LGBMRegressor\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier \n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(x_train)\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "x_test = minmax_scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "lgbm = LGBMRegressor(random_state=20) \n",
        "\n",
        "parameters = {'n_estimators':[80,90,100,110,120],'max_depth':[5, 10, 15, 20], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_lgbm = GridSearchCV(lgbm, param_grid=parameters, cv=2, refit=True)\n",
        "grid_lgbm.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_lgbm.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "swRM6mZgpLCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "ratios = [0.2, 0.5, 0.8]\n",
        "\n",
        "for ratio in ratios:\n",
        "    elasticnet = ElasticNet(alpha=0.5, l1_ratio=ratio)\n",
        "    elasticnet.fit(x_train, y_train)\n",
        "    pred = elasticnet.predict(x_test)\n"
      ],
      "metadata": {
        "id": "ghbyzCS7pVht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CatBoostRegressor\n",
        "import numpy as np\n",
        "from catboost import Pool, CatBoostRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(x_train)\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "x_test = minmax_scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "catboost1 = CatBoostRegressor(random_state=20) \n",
        "\n",
        "parameters = {'n_estimators':[100,110,120, 130, 140],'max_depth':[5, 10, 15, 20], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_cb = GridSearchCV(catboost1, param_grid=parameters, cv=2, refit=True)\n",
        "grid_cb.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_cb.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "rdrpsAP9pWEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost --no-cache-dir"
      ],
      "metadata": {
        "id": "xjc947w0pY1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge()\n",
        "train_score = []\n",
        "test_score = []\n",
        "alpha_list = [0.001,0.01, 0.1, 1, 10, 100]\n",
        "for alpha in alpha_list:\n",
        "  ridge = Ridge(alpha=alpha)\n",
        "  ridge.fit(x_train, y_train)\n",
        "  train_score.append(ridge.score(x_train, y_train))\n",
        "  test_score.append(ridge.score(x_test, y_test))\n",
        "print(ridge.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "PT3OqhpwpabL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso()\n",
        "train_score = []\n",
        "test_score = []\n",
        "alpha_list = [0.001,0.01, 0.1, 1, 10, 100]\n",
        "for alpha in alpha_list:\n",
        "  lasso = Lasso(alpha=alpha)\n",
        "  lasso.fit(x_train, y_train)\n",
        "  train_score.append(lasso.score(x_train, y_train))\n",
        "  test_score.append(lasso.score(x_test, y_test))\n",
        "print(lasso.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "r4XZ10LKpc3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Elastic Net\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "ratios = [0.2, 0.5, 0.8]\n",
        "\n",
        "for ratio in ratios:\n",
        "    elasticnet = ElasticNet(alpha=0.05, l1_ratio=ratio)\n",
        "    elasticnet.fit(x_train, y_train)\n",
        "    pred = elasticnet.predict(x_test)\n",
        "print(elasticnet.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "Hph4Qkh7pfad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "elasticnet_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    ElasticNet(alpha=0.1, l1_ratio=0.2)\n",
        ")\n",
        "\n",
        "elasticnet_pred = elasticnet_pipeline.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "print(elasticnet_pipeline.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "z1ORzufYpiJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Poly_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "poly_features = poly.fit_transform(x_train)[0]\n",
        "\n",
        "poly_pipeline = make_pipeline(\n",
        "    PolynomialFeatures(degree=2, include_bias=False),\n",
        "    StandardScaler(),\n",
        "    ElasticNet(alpha=0.1, l1_ratio=0.2)\n",
        ")\n",
        "\n",
        "poly_pred = poly_pipeline.fit(x_train, y_train).predict(x_test)\n",
        "print(poly_pipeline.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "bSjGlqVgpkvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VotingRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "single_models = [\n",
        "    ('ridge', ridge),\n",
        "    ('lasso', lasso),\n",
        "    ('elasticnet_pipeline', elasticnet_pipeline),\n",
        "    ('poly_pipeline', poly_pipeline)\n",
        "]\n",
        "\n",
        "voting_regressor = VotingRegressor(single_models, n_jobs=-1)\n",
        "voting_regressor.fit(x_train, y_train)\n",
        "voting_pred = voting_regressor.predict(x_test)\n",
        "\n",
        "print(voting_regressor.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "WPqildQwpnVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#StackingRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "stack_models = [\n",
        "    ('elasticnet', poly_pipeline),\n",
        "    ('randomforest', rf),\n",
        "    ('gbr', gbr),\n",
        "    ('lgbm', lgbm)\n",
        "]\n",
        "\n",
        "stack_reg = StackingRegressor(stack_models, final_estimator=xgb, n_jobs=-1)\n",
        "stack_reg.fit(x_train, y_train)\n",
        "stack_pred = stack_reg.predict(x_test)\n",
        "\n",
        "print(stack_reg.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "9K3YL8iZprK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xgboost\n",
        "from xgboost import XGBRegressor \n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_data22[features],df_data22[label], test_size=0.2, shuffle=True,random_state=10)\n",
        "\n",
        "# MinMaxScaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "minmax_scaler.fit(x_train)\n",
        "x_train = minmax_scaler.transform(x_train)\n",
        "x_test = minmax_scaler.transform(x_test)\n",
        "\n",
        "# Model\n",
        "xgb = XGBRegressor(random_state=20) \n",
        "\n",
        "parameters = {'n_estimators':[80,90,100,110,120],'max_depth':[5, 10, 15, 20], 'min_samples_split':[2,3,4,5,6]}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb, param_grid=parameters, cv=2, refit=True)\n",
        "grid_xgb.fit(x_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(grid_xgb.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score',\n",
        "           'split0_test_score', 'split1_test_score']]"
      ],
      "metadata": {
        "id": "bIg1uNcnpt9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}